[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi, friend. I’m Eric. If you’re interested in learning more about me, you can check out my personal site, where I occassionally blog and post stuff. You can also find me on Github"
  },
  {
    "objectID": "GCP/ci_cd_cloudrun.html",
    "href": "GCP/ci_cd_cloudrun.html",
    "title": "CI/CD with Cloud Run and Artifact Registry",
    "section": "",
    "text": "Below is an example cloudbuild.yaml file that will:\n\nBuild a Docker image using Cloud Build\nPush the built image to Artifact Registry\nDeploy the image to Cloud Run\n\nThere may be some additional setup/service account permissions that need to be specified (I’ll update this later once I sort these out), but at the very least, we need to create a repository in Artifact Registry first. To do that, run the following in gcloud:\ngcloud artifacts repositories create REPO_NAME --format docker --region us-east4\nFrom there, the cloudbuild.yaml file should look like this:\nsteps:\n  #docker build \n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['build', '-t',\n            'us-east4-docker.pkg.dev/${PROJECT_ID}/REPO_NAME/IMAGE_NAME:$COMMIT_SHA',\n            '.']\n  #docker push to artifact registry\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['push', 'us-east4-docker.pkg.dev/${PROJECT_ID}/REPO_NAME/IMAGE_NAME:$COMMIT_SHA']\n\n  #deploy the container to cloud run\n  - name: 'gcr.io/cloud-builders/gcloud'\n    args: ['run', 'deploy', 'SERVICE-NAME', '--image', 'us-east4-docker.pkg.dev/${PROJECT_ID}/REPO_NAME/IMAGE_NAME:$COMMIT_SHA', '--region', 'us-east4']\n\n#optional but prob worth setting\ntimeout: 3600s\nAnd then replace anything in ALL_CAPS above (without a $) with the relevant values"
  },
  {
    "objectID": "GCP/gcloud_cli_commands.html",
    "href": "GCP/gcloud_cli_commands.html",
    "title": "gcloud CLI Commands",
    "section": "",
    "text": "Check Projects\nTo list all of your projects:\ngcloud projects list\nTo check which project is your default project:\ngcloud config get-value project\nTo set which project is your default project:\ngcloud config set project [PROJECT_ID]\n\n\nCloud Storage\nTo push data to a cloud storage bucket:\ngcloud storage cp PATH/TO/LOCAL/FILE.PARQUET gs://BUCKET_NAME\nNote that cp in the above command means “copy.” See other flags/options here\n\n\nApp Engine\nTo deploy an app to App Engine:\ngcloud app deploy"
  },
  {
    "objectID": "Go/interface_composition.html",
    "href": "Go/interface_composition.html",
    "title": "Interface Composition",
    "section": "",
    "text": "One cool feature of Go is that it lets you compose interfaces using other interfaces. The prototypical example of this is the ReadWriter, which is composed of the Reader interface and the Writer interface.\nBelow is an example of a toy program that defines a UserStorer interface and an ItemStorer interface, then a Storer interface that is composed of these interfaces"
  },
  {
    "objectID": "Go/interface_composition.html#define-user-stuff",
    "href": "Go/interface_composition.html#define-user-stuff",
    "title": "Interface Composition",
    "section": "Define User Stuff",
    "text": "Define User Stuff\npackage main\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n)\n\n//create type\ntype User struct {\n    Name string\n    Age  int\n}\n\n//create interface\ntype UserStorer interface {\n    AddUser(users []*User, user *User) []*User\n}\n\n//define an empty struct that will implement interface\ntype ustore struct{}\n\n//constructor\nfunc NewUserStore() UserStorer {\n    return &ustore{}\n}\n\nfunc (us ustore) AddUser(users []*User, user *User) []*User {\n\n    users = append(users, user)\n\n    return users\n}"
  },
  {
    "objectID": "Go/interface_composition.html#define-item-stuff",
    "href": "Go/interface_composition.html#define-item-stuff",
    "title": "Interface Composition",
    "section": "Define Item Stuff",
    "text": "Define Item Stuff\n//define type\ntype Item struct {\n    Name  string\n    Usage string\n}\n\n//define interface\ntype ItemStorer interface {\n    AddItem(items []*Item, item *Item) []*Item\n}\n\n//define empty struct that will implement interface\ntype istore struct{}\n\n//define constructor\nfunc NewItemStore() ItemStorer {\n    return &istore{}\n}\n\n//define add method\nfunc (is istore) AddItem(items []*Item, item *Item) []*Item {\n\n    items = append(items, item)\n\n    return items\n}"
  },
  {
    "objectID": "Go/interface_composition.html#define-storer-stuff",
    "href": "Go/interface_composition.html#define-storer-stuff",
    "title": "Interface Composition",
    "section": "Define Storer Stuff",
    "text": "Define Storer Stuff\ntype Storer interface {\n    UserStorer\n    ItemStorer\n}\n\ntype myStore struct {\n    UserStorer\n    ItemStorer\n}\n\nfunc NewStorer(us UserStorer, is ItemStorer) Storer {\n\n    s := &myStore{\n        UserStorer: us,\n        ItemStorer: is,\n    }\n\n    return s\n}"
  },
  {
    "objectID": "Go/interface_composition.html#create-simple-program",
    "href": "Go/interface_composition.html#create-simple-program",
    "title": "Interface Composition",
    "section": "Create Simple Program",
    "text": "Create Simple Program\nfunc main() {\n\n    us := NewUserStore()\n    is := NewItemStore()\n\n    s := NewStorer(us, is)\n\n    var items []*Item\n    var users []*User\n\n    u := &User{\n        Name: \"Eric\",\n        Age:  34,\n    }\n\n    i := &Item{\n        Name:  \"Phone\",\n        Usage: \"texting\",\n    }\n\n    items = s.AddItem(items, i)\n    users = s.AddUser(users, u)\n\n    //embed to json\n    ji, _ := json.Marshal(items)\n    ju, _ := json.Marshal(users)\n\n    //print out results\n    fmt.Println(string(ji))\n    fmt.Println(string(ju))\n}"
  },
  {
    "objectID": "Go/parse_query_params.html",
    "href": "Go/parse_query_params.html",
    "title": "Parsing URL Query Parameters",
    "section": "",
    "text": "This is a small example of how to parse url query parameters in Go. I was learning this in service of another project, in which case I wanted the parameters in the map[string]string format, but this doesn’t always need to be the case.\npackage main\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n    \"strings\"\n)\n\nfunc DemoGet(w http.ResponseWriter, r *http.Request) {\n\n    urlParams := r.URL.Query()\n\n    //in a use case for another project, i want the urlParams to be encoded as a map[string]string\n    //but this won't always be the use case\n    m := make(map[string]string, len(urlParams))\n\n    for i, v := range urlParams {\n        //in prod, we probably don't want to error out\n        //but yolo for now\n        if len(v) &gt; 1 {\n            log.Fatal(\"query parameters should all be length 1\")\n        }\n        s := strings.Join(v, \"\")\n        m[i] = s\n    }\n\n    w.Header().Set(\"Content-Type\", \"application/json\")\n\n    json.NewEncoder(w).Encode(m)\n}\n\nfunc main() {\n    r := http.NewServeMux()\n\n    r.HandleFunc(\"/demoget\", DemoGet)\n\n    s := &http.Server{\n        Addr:    \":8080\",\n        Handler: r,\n    }\n\n    fmt.Println(\"Running demo program\")\n\n    s.ListenAndServe()\n}"
  },
  {
    "objectID": "Go/post_request_validation.html",
    "href": "Go/post_request_validation.html",
    "title": "Validating Post Requests",
    "section": "",
    "text": "This is a pretty small example of how to validate a post request in Go. It’s not at all difficult, but I’m writing this because I often forget to do this, and I’m hoping that writing it will make me remember.\npackage main\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n\n    \"github.com/go-playground/validator\"\n)\n\nconst (\n    listenAddr string = \":8080\"\n)\n\n//when defining the struct, be sure to indicate validation requirements\n//you can also do something like validate:\"required,email\" to check that the input is an email\ntype User struct {\n    FirstName string `json:\"firstName\" validate:\"required\"`\n    LastName  string `json:\"lastName\" validate:\"required\"`\n}\n\nfunc handleIndex(w http.ResponseWriter, r *http.Request) {\n\n    switch r.Method {\n    case http.MethodGet:\n        msg := \"hello, world\"\n\n        w.WriteHeader(http.StatusOK)\n\n        w.Write([]byte(msg))\n\n    case http.MethodPost:\n        var u *User\n\n        //create a new instance of a validator\n        validate := validator.New()\n\n        json.NewDecoder(r.Body).Decode(&u)\n\n        //validate the struct\n        err := validate.Struct(u)\n\n        if err != nil {\n            http.Error(w, \"invalid request\", http.StatusBadRequest)\n            return\n        }\n\n        msg := \"hello, \" + u.FirstName + \" \" + u.LastName\n\n        w.WriteHeader(http.StatusOK)\n\n        w.Write([]byte(msg))\n    default:\n        http.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n    }\n}\n\nfunc main() {\n    r := http.NewServeMux()\n\n    r.HandleFunc(\"/\", handleIndex)\n\n    fmt.Println(\"Running server\")\n\n    err := http.ListenAndServe(listenAddr, r)\n\n    log.Fatal(err)\n}"
  },
  {
    "objectID": "Go/test_http_server.html",
    "href": "Go/test_http_server.html",
    "title": "Testing an HTTP Server",
    "section": "",
    "text": "This is a small example of how to test an HTTP server endpoint. I’ve gotten in the bad habit of not writing tests for my Go code, and I need to brush up on how to write tests.\nI’ll likely do a better version of this later that uses mocks, but for now, this will suffice.\nThe code below is split into 3 different files:"
  },
  {
    "objectID": "Go/test_http_server.html#main.go",
    "href": "Go/test_http_server.html#main.go",
    "title": "Testing an HTTP Server",
    "section": "main.go",
    "text": "main.go\nThe contents of main.go are:\npackage main\n\nfunc main() {\n    s := NewServer()\n    s.Run()\n}\nThis file really just bundles everything together and runs the application"
  },
  {
    "objectID": "Go/test_http_server.html#server.go",
    "href": "Go/test_http_server.html#server.go",
    "title": "Testing an HTTP Server",
    "section": "server.go",
    "text": "server.go\nThe contents of server.go are:\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n)\n\n//define a user type\ntype User struct {\n    FirstName string\n    Age       int\n}\n\n//define a server type\ntype Server struct {\n    Srvr      *http.Server\n    UserStore []*User\n}\n\n//create a new server with some dummy data included\nfunc NewServer() *Server {\n    return &Server{\n        Srvr: &http.Server{\n            Addr: \":8080\",\n        },\n\n        UserStore: []*User{\n            {\n                FirstName: \"John\",\n                Age:       29,\n            },\n            {\n                FirstName: \"Kendall\",\n                Age:       32,\n            },\n        },\n    }\n}\n\n//define a function to handle an endpoint requesting the user's age\nfunc (s *Server) HandleGetUserAge(w http.ResponseWriter, r *http.Request) {\n    q := r.URL.Query()\n    firstName := q.Get(\"first_name\")\n\n    for _, user := range s.UserStore {\n        if user.FirstName == firstName {\n            w.WriteHeader(http.StatusOK)\n            fmt.Fprint(w, user.Age)\n            return\n        }\n    }\n\n    w.WriteHeader(http.StatusNotFound)\n    fmt.Fprint(w, \"user not found\")\n}\n\n//run the server\nfunc (s *Server) Run() {\n    http.HandleFunc(\"/user\", s.HandleGetUserAge)\n    s.Srvr.ListenAndServe()\n}\nThis is all fairly self explanatory."
  },
  {
    "objectID": "Go/test_http_server.html#server_test.go",
    "href": "Go/test_http_server.html#server_test.go",
    "title": "Testing an HTTP Server",
    "section": "server_test.go",
    "text": "server_test.go\nThe contents of server_test.go, which is the thing I’m actually interested in here, are:\npackage main\n\n//write a test for the handleGetUserAge endpoint\n\nimport (\n    \"net/http\"\n    \"net/http/httptest\"\n    \"testing\"\n)\n\nfunc TestHandleGetUserAge(t *testing.T) {\n    req, err := http.NewRequest(\"GET\", \"/user?first_name=John\", nil) //create a request\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    //note that creating a mock with a datastore is probably a better way to do this, but I defined the handler above as a method on the server, so I need another server here\n    s := NewServer() //create a new server\n\n    rr := httptest.NewRecorder()                    //create a response recorder, which is a tool that lets us test http responses\n    handler := http.HandlerFunc(s.HandleGetUserAge) //create a handler function\n\n    handler.ServeHTTP(rr, req) //call the handler function\n    //note that since rr is a pointer, its data can be updated when this handler is called\n\n    if status := rr.Code; status != http.StatusOK { //check the status code\n        t.Errorf(\"handler returned wrong status code: got %v want %v\",\n            status, http.StatusOK)\n    }\n\n    expected := \"29\"        //expected response. We know this is what shoul be returned since this is John's age in the dummy data we created\n    got := rr.Body.String() //get the response body\n    if got != expected {    //check the response body\n        t.Errorf(\"handler returned unexpected body: got %v want %v\",\n            got, expected)\n    }\n}\nIf we run the test, we’ll see that it passes."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "leakybrain",
    "section": "",
    "text": "Welcome to leakybrain.\nThis is a site I created to drop random snippets of code and take notes related to programming, statistics, and other related topics. It was inspired by Vicki Boykis’s BoringML project."
  },
  {
    "objectID": "Julia/julia_pkg_init.html",
    "href": "Julia/julia_pkg_init.html",
    "title": "Julia Package Initialization",
    "section": "",
    "text": "Interactive Pkg Creation\nCreating packages is probably easiest to do interactively – it’s hard to remember all of the potential arguments/configurations you want, and the “interactive mode” of PkgTemplates does a nice job of walking you through package creation.\nThe approach is pretty straightforward:\nusing PkgTemplates\nTemplate(interactive=true)(\"MyPkg\")\n\n\nNon-Interactive Pkg Creation\nYou can also do this non-interactively by running the Template() function with all of the arguments you want. But again, it’s hard to remember everything since you (or at least I) don’t make packages all that often.\nBut you can do it non-interactively like so:\nusing PkgTemplates\n\nt = Template(;\n    user = \"ekholme\", #or your git user.name\n    license = \"MIT\",\n    authors = [\"Eric Ekholm\"],\n    julia_version = v\"1.8\", #or w/e version you want\n    plugins = [\n        GitHubActions(),\n        Codecov(),\n        GitHubPages(),\n        TravisCI()\n    ]\n)\n\nt(\"MyPkgName\")\nAnd then running this will create a new package (and set up all of your Git stuff if it’s already configured)"
  },
  {
    "objectID": "Julia/load_dev_pkg.html",
    "href": "Julia/load_dev_pkg.html",
    "title": "Install a Local Dev Pkg",
    "section": "",
    "text": "Sometimes it’s helpful to be able to load/install a local Julia package. We can do this as follows:\n]\ndev path/to/pkg\nwhere the path to the pkg is probably going to be something like .julia/dev/MyPkg"
  },
  {
    "objectID": "Julia/mlj_pipeline.html",
    "href": "Julia/mlj_pipeline.html",
    "title": "MLJ Pipeline",
    "section": "",
    "text": "Below is a minimal (yet complete) example of a machine learning pipeline that use’s Julia’s MLJ framework and the Palmer Penguins dataset.\nNote that the goal here isn’t necessarily to fit the best model; rather it’s just to demonstrate an MLJ pipeline.\n\nusing DataFrames\nusing CSV\nusing Random\nusing MLJ\n\nRandom.seed!(0408)\n\n#get penguins data\npenguins = CSV.read(download(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv\"), DataFrame, missingstring=\"NA\")\n\n#filter to those without missing body mass\ndropmissing!(penguins, :body_mass_g)\n\n#extract body mass as y\ny, X = unpack(penguins, ==(:body_mass_g))\n\n# coercing textual columns to multiclass for modeling\ncoerce_nms = [:species, :sex, :island]\n\nc_dict = Dict(zip(coerce_nms, repeat([Multiclass], 3)))\n\ncoerce!(\n    X,\n    c_dict\n)\n\n#get training and validation indices\ntrn, val = partition(eachindex(y), 0.8; shuffle=true)\n\n#define pipeline components\nimp = FillImputer();\nstand = Standardizer();\noh = OneHotEncoder(drop_last=true);\nLinearRegression = @load LinearRegressor pkg = GLM add = true\nmod = LinearRegression()\n\n#define pipeline\nm = Pipeline(imp, stand, oh, mod)\n\n#define machine\nmach = machine(m, X, y);\n\n#fit machine on training rows\nfit!(mach, rows=trn)\n\n#predicting training y's\nŷ = MLJ.predict_mean(mach, X[trn, :])\n\n#evaluate model\ncv = CV(nfolds=3)\n\nMLJ.evaluate!(mach, rows=val, resampling=cv, measure=rmse)\n\n#note -- call measures() to see all available measures\n\n┌ Info: Trying to coerce from `Union{Missing, String7}` to `Multiclass`.\n└ Coerced to `Union{Missing,Multiclass}` instead.\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(ProbabilisticPipeline(fill_imputer = FillImputer(features = Symbol[], …), …), …).\n[ Info: Training machine(:fill_imputer, …).\n[ Info: Training machine(:standardizer, …).\n[ Info: Training machine(:one_hot_encoder, …).\n[ Info: Spawning 2 sub-features to one-hot encode feature :species.\n[ Info: Spawning 2 sub-features to one-hot encode feature :island.\n[ Info: Spawning 1 sub-features to one-hot encode feature :sex.\n[ Info: Training machine(:linear_regressor, …).\n[ Info: Creating subsamples from a subset of all rows. \nEvaluating over 3 folds:  67%[================&gt;        ]  ETA: 0:00:01Evaluating over 3 folds: 100%[=========================] Time: 0:00:02\n\n\nimport MLJGLMInterface ✔\n\n\n\nPerformanceEvaluation object with these fields:\n  measure, operation, measurement, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_rows\nExtract:\n┌────────────────────────┬──────────────┬─────────────┬─────────┬───────────────\n│ measure                │ operation    │ measurement │ 1.96*SE │ per_fold     ⋯\n├────────────────────────┼──────────────┼─────────────┼─────────┼───────────────\n│ RootMeanSquaredError() │ predict_mean │ 342.0       │ 94.8    │ [277.0, 322. ⋯\n└────────────────────────┴──────────────┴─────────────┴─────────┴───────────────\n                                                                1 column omitted"
  },
  {
    "objectID": "Julia/struct_vector.html",
    "href": "Julia/struct_vector.html",
    "title": "Inititializing a Vector of Structs",
    "section": "",
    "text": "Here’s an example of how to initialize a vector of structs in Julia. It’s sometimes useful to coerce other data structures into vectors of structs to perform operations on them, and so this snippet provides a basic example of creating and populating a vector of a custom struct\n\nLoad Pkgs and Define Struct\n\nusing Random #for creating data\n\n#define struct\nmutable struct MyType\n  x::String\n  y::Int64\n  z::Vector{Float64}\nend\n\n#instantiate an example struct\na = MyType(\"hello\", 1, [1., 1.5, 104.1])\n\nMyType(\"hello\", 1, [1.0, 1.5, 104.1])\n\n\n\n\nCreate a Constructor\nThis isn’t strictly necessary, but it can be useful. This just creates a new instance of MyType with random values\n\nfunction MyType()\n    MyType(randstring(10), rand(1:100), rand(Float64, 3))\nend\n\na = MyType()\n\nMyType(\"WAc1LBvkFm\", 33, [0.3619946274985777, 0.858479824777187, 0.720193448993144])\n\n\n\n\nCreate an Empty n-vector, then Populate It\n\nn = 100\n\n#initialize an n-vector with 0 values\nv = Vector{MyType}(undef, n)\n\n#populate the vector\nfor i ∈ eachindex(v)\n    v[i] = MyType()\nend\n\n\n\nCheck Results\nwe want v to be a vector of MyType\n\ntypeof(v)\n\n\nVector{MyType} (alias for Array{MyType, 1})\n\n\n\nand we want each element to be MyType\n\ntypeof(v[1])\n\nMyType\n\n\nand let’s check the first element\n\nv[1]\n\nMyType(\"HmSiEUvtnk\", 24, [0.22658234942156086, 0.5284152678374769, 0.48072129238569283])"
  },
  {
    "objectID": "Python/basics_classes.html",
    "href": "Python/basics_classes.html",
    "title": "Basics - Classes",
    "section": "",
    "text": "The stuff below is like Python classes 101. It’s mostly either directly copied from or else loosely inspired by the Python manual\n# define a new class\nclass MyClass:\n    x = 123\n\n    def greet(self):\n        return \"Hello from MyClass\"\n\n\nx = MyClass()\n\n# see class attributes\nx.greet()\nx.x\n\n123"
  },
  {
    "objectID": "Python/basics_classes.html#init-method",
    "href": "Python/basics_classes.html#init-method",
    "title": "Basics - Classes",
    "section": "Init Method",
    "text": "Init Method\n\n# we can define an __init()__ method to help us create object instances with specific initial states\nclass MyClass:\n    def __init__(self, x):\n        self.x = x\n\n    def greet(self):\n        return \"Hello from MyClass\"\n\n\ny = MyClass(x=1)\ny.x\n\n1"
  },
  {
    "objectID": "Python/basics_classes.html#class-variables-and-instance-variables",
    "href": "Python/basics_classes.html#class-variables-and-instance-variables",
    "title": "Basics - Classes",
    "section": "Class Variables and Instance Variables",
    "text": "Class Variables and Instance Variables\n\n# class variables will be shared by all instances, whereas instance variables will be unique to each instance\nclass Dog:\n    kind = \"canine\"  # class variable\n\n    def __init__(self, name):\n        self.name = name\n\n\nd = Dog(\"Nala\")\ne = Dog(\"Adi\")\n\nd.name\nd.kind\ne.name\n\n\n# below might be a way to create a Dog class where each dog has its own set of tricks\nclass Dog:\n    kind = \"canine\"\n\n    def __init__(self, name):\n        self.name = name\n        self.tricks = []\n\n    def add_trick(self, trick):\n        self.tricks.append(trick)\n\n\nd = Dog(\"Nala\")\nd.add_trick(\"roll over\")\nd.add_trick(\"sit\")\n\nd.tricks\n\n['roll over', 'sit']"
  },
  {
    "objectID": "Python/basics_classes.html#class-inheritance",
    "href": "Python/basics_classes.html#class-inheritance",
    "title": "Basics - Classes",
    "section": "Class Inheritance",
    "text": "Class Inheritance\nClass inheritance lets classes inherit variables and methods from other classes\n\n# classes also support inheritance\nclass Animal:\n    def __init__(self, name):\n        self.name = name\n\n\nclass Cat(Animal):\n    kind = \"cat\"\n\n\na = Cat(\"Fluffy\")\n\na.name\na.kind\n\n'cat'"
  },
  {
    "objectID": "Python/polars_cheat_sheet.html",
    "href": "Python/polars_cheat_sheet.html",
    "title": "Polars Cheat Sheet",
    "section": "",
    "text": "Setup & Read in Data\n\nimport polars.selectors as cs\nimport polars as pl\n\n# read in data\npenguins = pl.read_csv(\n    \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv\",\n    null_values=\"NA\",\n)\n\n\n\nCheck Properties of a Dataframe\nuse the shape attribute to check the dimensions (rows, cols)\n\npenguins.shape\n\n(344, 8)\n\n\nuse the head() method to see the first few rows\n\npenguins.head()\n\n\nshape: (5, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\ni64\ni64\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181\n3750\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186\n3800\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195\n3250\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\nnull\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193\n3450\n\"female\"\n2007\n\n\n\n\n\n\nto see the column names, we can use the columns attribute\n\npenguins.columns\n\n['species',\n 'island',\n 'bill_length_mm',\n 'bill_depth_mm',\n 'flipper_length_mm',\n 'body_mass_g',\n 'sex',\n 'year']\n\n\n\n\nSubset Rows\nFor the most part, we want to subset rows using the filter() method.\nFor example, we might want to filter out rows that aren’t missing data for the body mass variable\n\npenguins.filter(pl.col(\"body_mass_g\").is_not_null())\n\n\nshape: (342, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\ni64\ni64\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181\n3750\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186\n3800\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195\n3250\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193\n3450\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190\n3650\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181\n3625\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195\n4675\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193\n3475\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190\n4250\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186\n3300\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180\n3700\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n41.1\n17.6\n182\n3200\n\"female\"\n2007\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n45.2\n16.6\n191\n3250\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n49.3\n19.9\n203\n4050\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.8\n202\n3800\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n45.6\n19.4\n194\n3525\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n51.9\n19.5\n206\n3950\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n46.8\n16.5\n189\n3650\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n45.7\n17.0\n195\n3650\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n55.8\n19.8\n207\n4000\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n43.5\n18.1\n202\n3400\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n49.6\n18.2\n193\n3775\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.8\n19.0\n210\n4100\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.7\n198\n3775\n\"female\"\n2009\n\n\n\n\n\n\nBasically, filter keeps rows where the expression evaluates to True. And so we can use any predicate expression that results in a boolean. We can also use multiple expressions.\n\npenguins.filter((pl.col(\"species\") == \"Adelie\") & (pl.col(\"bill_length_mm\") &gt;= 39.0))\n\n\nshape: (72, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\ni64\ni64\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181\n3750\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186\n3800\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195\n3250\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190\n3650\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195\n4675\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190\n4250\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n41.1\n17.6\n182\n3200\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n42.5\n20.7\n197\n4500\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n46.0\n21.5\n194\n4200\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Biscoe\"\n40.6\n18.6\n183\n3550\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Biscoe\"\n40.5\n17.9\n187\n3200\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Biscoe\"\n40.5\n18.9\n180\n3950\n\"male\"\n2007\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Adelie\"\n\"Torgersen\"\n39.0\n17.1\n191\n3050\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n44.1\n18.0\n210\n4000\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n43.1\n19.2\n197\n3500\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n41.1\n17.5\n190\n3900\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n40.2\n20.1\n200\n3975\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n39.7\n17.9\n193\n4250\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n40.2\n17.1\n193\n3400\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n40.6\n17.2\n187\n3475\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n40.7\n17.0\n190\n3725\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n39.0\n18.7\n185\n3650\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n39.2\n18.6\n190\n4250\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Dream\"\n41.5\n18.5\n201\n4000\n\"male\"\n2009\n\n\n\n\n\n\nWe might also want to filter based on string matches. For example, strings that start with a certain substring\n\npenguins.filter(pl.col(\"species\").str.starts_with(\"Chin\"))\n\n\nshape: (68, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\ni64\ni64\nstr\ni64\n\n\n\n\n\"Chinstrap\"\n\"Dream\"\n46.5\n17.9\n192\n3500\n\"female\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n50.0\n19.5\n196\n3900\n\"male\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n51.3\n19.2\n193\n3650\n\"male\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n45.4\n18.7\n188\n3525\n\"female\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n52.7\n19.8\n197\n3725\n\"male\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n45.2\n17.8\n198\n3950\n\"female\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n46.1\n18.2\n178\n3250\n\"female\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n51.3\n18.2\n197\n3750\n\"male\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n46.0\n18.9\n195\n4150\n\"female\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n51.3\n19.9\n198\n3700\n\"male\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n46.6\n17.8\n193\n3800\n\"female\"\n2007\n\n\n\"Chinstrap\"\n\"Dream\"\n51.7\n20.3\n194\n3775\n\"male\"\n2007\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n45.2\n16.6\n191\n3250\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n49.3\n19.9\n203\n4050\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.8\n202\n3800\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n45.6\n19.4\n194\n3525\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n51.9\n19.5\n206\n3950\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n46.8\n16.5\n189\n3650\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n45.7\n17.0\n195\n3650\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n55.8\n19.8\n207\n4000\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n43.5\n18.1\n202\n3400\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n49.6\n18.2\n193\n3775\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.8\n19.0\n210\n4100\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.7\n198\n3775\n\"female\"\n2009\n\n\n\n\n\n\n\n\nSubset Columns\nTo subset columns, we want to use the select() method.\n\npenguins.select(\"species\")\n\n\nshape: (344, 1)\n\n\n\nspecies\n\n\nstr\n\n\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n\"Adelie\"\n\n\n…\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\"Chinstrap\"\n\n\n\n\n\n\nTo select multiple columns, we pass in a list\n\npenguins.select([\"species\", \"island\"])\n\n\nshape: (344, 2)\n\n\n\nspecies\nisland\n\n\nstr\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\n\n\n\nTo select columns with regex, we can pass regex to pl.col(). Note that we need to indicate this is regex by passing both ^ and $.\n\npenguins.select(pl.col(\"^bill_.*$\"))\n\n\nshape: (344, 2)\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\nf64\nf64\n\n\n\n\n39.1\n18.7\n\n\n39.5\n17.4\n\n\n40.3\n18.0\n\n\nnull\nnull\n\n\n36.7\n19.3\n\n\n39.3\n20.6\n\n\n38.9\n17.8\n\n\n39.2\n19.6\n\n\n34.1\n18.1\n\n\n42.0\n20.2\n\n\n37.8\n17.1\n\n\n37.8\n17.3\n\n\n…\n…\n\n\n45.2\n16.6\n\n\n49.3\n19.9\n\n\n50.2\n18.8\n\n\n45.6\n19.4\n\n\n51.9\n19.5\n\n\n46.8\n16.5\n\n\n45.7\n17.0\n\n\n55.8\n19.8\n\n\n43.5\n18.1\n\n\n49.6\n18.2\n\n\n50.8\n19.0\n\n\n50.2\n18.7\n\n\n\n\n\n\nand we can also exclude by regex\n\npenguins.select(pl.exclude(\"^bill_.*$\"))\n\n\nshape: (344, 6)\n\n\n\nspecies\nisland\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\ni64\ni64\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n181\n3750\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n186\n3800\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n195\n3250\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n193\n3450\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n190\n3650\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n181\n3625\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n195\n4675\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n193\n3475\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n190\n4250\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n186\n3300\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n180\n3700\nnull\n2007\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n191\n3250\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n203\n4050\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n202\n3800\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n194\n3525\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n206\n3950\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n189\n3650\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n195\n3650\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n207\n4000\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n202\n3400\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n193\n3775\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n210\n4100\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n198\n3775\n\"female\"\n2009\n\n\n\n\n\n\nPolars (via the polars.selectors module) also provides utilities similar to tidyverse selectors, such as starts_with()\n\npenguins.select(cs.starts_with(\"bill\"))\n\n\nshape: (344, 2)\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\nf64\nf64\n\n\n\n\n39.1\n18.7\n\n\n39.5\n17.4\n\n\n40.3\n18.0\n\n\nnull\nnull\n\n\n36.7\n19.3\n\n\n39.3\n20.6\n\n\n38.9\n17.8\n\n\n39.2\n19.6\n\n\n34.1\n18.1\n\n\n42.0\n20.2\n\n\n37.8\n17.1\n\n\n37.8\n17.3\n\n\n…\n…\n\n\n45.2\n16.6\n\n\n49.3\n19.9\n\n\n50.2\n18.8\n\n\n45.6\n19.4\n\n\n51.9\n19.5\n\n\n46.8\n16.5\n\n\n45.7\n17.0\n\n\n55.8\n19.8\n\n\n43.5\n18.1\n\n\n49.6\n18.2\n\n\n50.8\n19.0\n\n\n50.2\n18.7\n\n\n\n\n\n\nAnother useful feature is selecting by data type. This is something that polars.selectors enables. For instance, if we wanted to select all numeric columns\n\npenguins.select(cs.by_dtype(pl.NUMERIC_DTYPES))\n\n\nshape: (344, 5)\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\nf64\nf64\ni64\ni64\ni64\n\n\n\n\n39.1\n18.7\n181\n3750\n2007\n\n\n39.5\n17.4\n186\n3800\n2007\n\n\n40.3\n18.0\n195\n3250\n2007\n\n\nnull\nnull\nnull\nnull\n2007\n\n\n36.7\n19.3\n193\n3450\n2007\n\n\n39.3\n20.6\n190\n3650\n2007\n\n\n38.9\n17.8\n181\n3625\n2007\n\n\n39.2\n19.6\n195\n4675\n2007\n\n\n34.1\n18.1\n193\n3475\n2007\n\n\n42.0\n20.2\n190\n4250\n2007\n\n\n37.8\n17.1\n186\n3300\n2007\n\n\n37.8\n17.3\n180\n3700\n2007\n\n\n…\n…\n…\n…\n…\n\n\n45.2\n16.6\n191\n3250\n2009\n\n\n49.3\n19.9\n203\n4050\n2009\n\n\n50.2\n18.8\n202\n3800\n2009\n\n\n45.6\n19.4\n194\n3525\n2009\n\n\n51.9\n19.5\n206\n3950\n2009\n\n\n46.8\n16.5\n189\n3650\n2009\n\n\n45.7\n17.0\n195\n3650\n2009\n\n\n55.8\n19.8\n207\n4000\n2009\n\n\n43.5\n18.1\n202\n3400\n2009\n\n\n49.6\n18.2\n193\n3775\n2009\n\n\n50.8\n19.0\n210\n4100\n2009\n\n\n50.2\n18.7\n198\n3775\n2009\n\n\n\n\n\n\n\n\nCreating New Columns\nTo create new columns, we’ll use the with_columns() method, which is similar to dplyr::mutate()\n\npenguins.with_columns(is_chinstrap=pl.col(\"species\") == \"Chinstrap\")\n\n\nshape: (344, 9)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nis_chinstrap\n\n\nstr\nstr\nf64\nf64\ni64\ni64\nstr\ni64\nbool\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181\n3750\n\"male\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186\n3800\n\"female\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195\n3250\n\"female\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\nnull\nnull\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193\n3450\n\"female\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190\n3650\n\"male\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181\n3625\n\"female\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195\n4675\n\"male\"\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193\n3475\nnull\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190\n4250\nnull\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186\n3300\nnull\n2007\nfalse\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180\n3700\nnull\n2007\nfalse\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n45.2\n16.6\n191\n3250\n\"female\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n49.3\n19.9\n203\n4050\n\"male\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.8\n202\n3800\n\"male\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n45.6\n19.4\n194\n3525\n\"female\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n51.9\n19.5\n206\n3950\n\"male\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n46.8\n16.5\n189\n3650\n\"female\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n45.7\n17.0\n195\n3650\n\"female\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n55.8\n19.8\n207\n4000\n\"male\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n43.5\n18.1\n202\n3400\n\"female\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n49.6\n18.2\n193\n3775\n\"male\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n50.8\n19.0\n210\n4100\n\"male\"\n2009\ntrue\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.7\n198\n3775\n\"female\"\n2009\ntrue\n\n\n\n\n\n\nWe can create multiple columns at a time\n\npenguins.with_columns(\n    is_chinstrap=pl.col(\"species\") == \"Chinstrap\",\n    chonk=pl.col(\"body_mass_g\") &gt;= 4000,\n    bill_stuff=pl.col(\"bill_length_mm\") + pl.col(\"bill_depth_mm\"),\n    sex_initial=pl.col(\"sex\").str.slice(0, 1).str.to_uppercase(),\n)\n\n\nshape: (344, 12)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nis_chinstrap\nchonk\nbill_stuff\nsex_initial\n\n\nstr\nstr\nf64\nf64\ni64\ni64\nstr\ni64\nbool\nbool\nf64\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181\n3750\n\"male\"\n2007\nfalse\nfalse\n57.8\n\"M\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186\n3800\n\"female\"\n2007\nfalse\nfalse\n56.9\n\"F\"\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195\n3250\n\"female\"\n2007\nfalse\nfalse\n58.3\n\"F\"\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\nnull\nnull\n2007\nfalse\nnull\nnull\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193\n3450\n\"female\"\n2007\nfalse\nfalse\n56.0\n\"F\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190\n3650\n\"male\"\n2007\nfalse\nfalse\n59.9\n\"M\"\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181\n3625\n\"female\"\n2007\nfalse\nfalse\n56.7\n\"F\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195\n4675\n\"male\"\n2007\nfalse\ntrue\n58.8\n\"M\"\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193\n3475\nnull\n2007\nfalse\nfalse\n52.2\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190\n4250\nnull\n2007\nfalse\ntrue\n62.2\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186\n3300\nnull\n2007\nfalse\nfalse\n54.9\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180\n3700\nnull\n2007\nfalse\nfalse\n55.1\nnull\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n45.2\n16.6\n191\n3250\n\"female\"\n2009\ntrue\nfalse\n61.8\n\"F\"\n\n\n\"Chinstrap\"\n\"Dream\"\n49.3\n19.9\n203\n4050\n\"male\"\n2009\ntrue\ntrue\n69.2\n\"M\"\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.8\n202\n3800\n\"male\"\n2009\ntrue\nfalse\n69.0\n\"M\"\n\n\n\"Chinstrap\"\n\"Dream\"\n45.6\n19.4\n194\n3525\n\"female\"\n2009\ntrue\nfalse\n65.0\n\"F\"\n\n\n\"Chinstrap\"\n\"Dream\"\n51.9\n19.5\n206\n3950\n\"male\"\n2009\ntrue\nfalse\n71.4\n\"M\"\n\n\n\"Chinstrap\"\n\"Dream\"\n46.8\n16.5\n189\n3650\n\"female\"\n2009\ntrue\nfalse\n63.3\n\"F\"\n\n\n\"Chinstrap\"\n\"Dream\"\n45.7\n17.0\n195\n3650\n\"female\"\n2009\ntrue\nfalse\n62.7\n\"F\"\n\n\n\"Chinstrap\"\n\"Dream\"\n55.8\n19.8\n207\n4000\n\"male\"\n2009\ntrue\ntrue\n75.6\n\"M\"\n\n\n\"Chinstrap\"\n\"Dream\"\n43.5\n18.1\n202\n3400\n\"female\"\n2009\ntrue\nfalse\n61.6\n\"F\"\n\n\n\"Chinstrap\"\n\"Dream\"\n49.6\n18.2\n193\n3775\n\"male\"\n2009\ntrue\nfalse\n67.8\n\"M\"\n\n\n\"Chinstrap\"\n\"Dream\"\n50.8\n19.0\n210\n4100\n\"male\"\n2009\ntrue\ntrue\n69.8\n\"M\"\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.7\n198\n3775\n\"female\"\n2009\ntrue\nfalse\n68.9\n\"F\"\n\n\n\n\n\n\nI’ll likely add more examples here as I encounter common use cases.\n\n\nSummarizing DataFrames\nMost summarizing workflows will involve the groupby() method, followed by some other operation.\nProbably the most common thing we’ll want to do is count by group\n\npenguins.groupby(\"island\").count()\n\n\nshape: (3, 2)\n\n\n\nisland\ncount\n\n\nstr\nu32\n\n\n\n\n\"Dream\"\n124\n\n\n\"Biscoe\"\n168\n\n\n\"Torgersen\"\n52\n\n\n\n\n\n\nWe can also group by multiple columns\n\npenguins.groupby([\"island\", \"species\"]).count()\n\n\nshape: (5, 3)\n\n\n\nisland\nspecies\ncount\n\n\nstr\nstr\nu32\n\n\n\n\n\"Torgersen\"\n\"Adelie\"\n52\n\n\n\"Biscoe\"\n\"Gentoo\"\n124\n\n\n\"Dream\"\n\"Chinstrap\"\n68\n\n\n\"Dream\"\n\"Adelie\"\n56\n\n\n\"Biscoe\"\n\"Adelie\"\n44\n\n\n\n\n\n\nAnother common thing might be to take the average of a numeric column by group. We can do this via the agg() method and passing various aggregation/summarization functions to this method.\n\npenguins.groupby(\"species\").agg(pl.mean(\"bill_length_mm\").alias(\"bill_length_mean\"))\n\n\nshape: (3, 2)\n\n\n\nspecies\nbill_length_mean\n\n\nstr\nf64\n\n\n\n\n\"Chinstrap\"\n48.833824\n\n\n\"Adelie\"\n38.791391\n\n\n\"Gentoo\"\n47.504878\n\n\n\n\n\n\nWe might also want to get the average of all of our numeric types by group. This is another situation where the polars.selectors module is helpful.\n\npenguins.groupby(\"species\").agg(cs.by_dtype(pl.NUMERIC_DTYPES).mean().suffix(\"_mean\"))\n\n\nshape: (3, 6)\n\n\n\nspecies\nbill_length_mm_mean\nbill_depth_mm_mean\nflipper_length_mm_mean\nbody_mass_g_mean\nyear_mean\n\n\nstr\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Adelie\"\n38.791391\n18.346358\n189.953642\n3700.662252\n2008.013158\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n195.823529\n3733.088235\n2007.970588\n\n\n\"Gentoo\"\n47.504878\n14.982114\n217.186992\n5076.01626\n2008.080645\n\n\n\n\n\n\nOr we might want to apply multiple aggregation functions to a column. This works basically like with_columns() in that you can pass multiple expressions\n\npenguins.groupby(\"species\").agg(\n    pl.mean(\"bill_length_mm\").alias(\"bill_length_mean\"),\n    pl.col(\"bill_length_mm\").count().alias(\"n\"),\n)\n\n\nshape: (3, 3)\n\n\n\nspecies\nbill_length_mean\nn\n\n\nstr\nf64\nu32\n\n\n\n\n\"Chinstrap\"\n48.833824\n68\n\n\n\"Gentoo\"\n47.504878\n124\n\n\n\"Adelie\"\n38.791391\n152\n\n\n\n\n\n\n\n\nReshaping Long and Wide\nLet’s take our summary from before where we calculated the average of all of the numeric columns by species\n\nspecies_means = penguins.groupby(\"species\").agg(cs.by_dtype(pl.NUMERIC_DTYPES).mean())\n\nNow suppose we want to pivot this longer so that it’s in “tidy” format. To do this, we want the melt() method.\n\nspecies_long = species_means.melt(id_vars=\"species\")\n\nspecies_long.head()\n\n\nshape: (5, 3)\n\n\n\nspecies\nvariable\nvalue\n\n\nstr\nstr\nf64\n\n\n\n\n\"Chinstrap\"\n\"bill_length_mm…\n48.833824\n\n\n\"Adelie\"\n\"bill_length_mm…\n38.791391\n\n\n\"Gentoo\"\n\"bill_length_mm…\n47.504878\n\n\n\"Chinstrap\"\n\"bill_depth_mm\"\n18.420588\n\n\n\"Adelie\"\n\"bill_depth_mm\"\n18.346358\n\n\n\n\n\n\nNote that in the above, there’s also a value_vars parameter. By leaving it empty, it defaults to every column not in id_vars, but this might not always be the right choice.\nAnd if we want to reshape back to wide, we use pivot(). Pivot can optionally perform aggregations while reshaping, so we need to tell it that we don’t want it to aggregate anything (by passing aggregate_function=None)\n\n species_long.pivot(values=\"value\", index=\"species\", columns=\"variable\", aggregate_function=None)\n\n\nshape: (3, 6)\n\n\n\nspecies\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\nstr\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n195.823529\n3733.088235\n2007.970588\n\n\n\"Adelie\"\n38.791391\n18.346358\n189.953642\n3700.662252\n2008.013158\n\n\n\"Gentoo\"\n47.504878\n14.982114\n217.186992\n5076.01626\n2008.080645"
  },
  {
    "objectID": "Python/sklearn_pipeline.html",
    "href": "Python/sklearn_pipeline.html",
    "title": "Scikit-Learn Pipeline",
    "section": "",
    "text": "Below is a minimal (yet complete) example of a machine learning pipeline using python and scikit-learn and the Palmer Penguins dataset.\nNote that the goal here isn’t necessarily to fit the best model; rather it’s just to demonstrate an sklearn pipeline. Also note that I wouldn’t call myself an expert python programmer, so there may be better/more efficient ways to do this.\n\nimport polars as pl\nimport numpy as np\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error\n\npenguins = pl.read_csv(\n    \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv\",\n    null_values=\"NA\",\n)\n\n# filtering to only rows with available body mass data\npenguins_complete = penguins.filter(pl.col(\"body_mass_g\").is_not_null())\n\n# coercing null to nan\npenguins_complete = penguins_complete.with_columns(pl.all().fill_null(np.nan))\n\n# separate into X and y\ny = penguins_complete[\"body_mass_g\"]\nX = penguins_complete.select(pl.exclude(\"body_mass_g\"))\n\n# coerce X to pandas since polars dfs don't seem to be supported for all of the sklearn steps yet\nX = X.to_pandas()\n\n# train test split\nX_trn, X_tst, y_trn, y_tst = train_test_split(X, y, random_state=408)\n\n# create pipeline for categorical features\ncat_feats = [\"species\", \"island\", \"sex\"]\ncat_transform = Pipeline(\n    [\n        (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"oh_encoder\", OneHotEncoder(drop=\"first\")),\n    ]\n)\n\n# create pipeline for numerical features\ncont_feats = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"year\"]\ncont_transform = Pipeline(\n    [\n        (\"cont_imputer\", SimpleImputer(strategy=\"mean\")),\n        (\"standardizer\", StandardScaler()),\n    ]\n)\n\n# create a preprocessing pipeline\npreprocessor = ColumnTransformer(\n    [(\"cats\", cat_transform, cat_feats), (\"conts\", cont_transform, cont_feats)]\n)\n\n# make full pipeline\npipe = Pipeline([(\"preprocess\", preprocessor), (\"lin_reg\", LinearRegression())])\n\n# fit pipeline\npipe.fit(X_trn, y_trn)\n\n# predict training y's\ny_hat = pipe.predict(X_trn)\n\n# evaluate model\ny_hat_tst = pipe.predict(X_tst)\n\nmath.sqrt(mean_squared_error(y_tst, y_hat_tst))\n\n295.1333053249438"
  },
  {
    "objectID": "Python/venv.html",
    "href": "Python/venv.html",
    "title": "venvs in Python",
    "section": "",
    "text": "To create a venv:\npython3.11 -m venv ./venv\nand to activate it:\nsource venv/bin/activate\net voila"
  },
  {
    "objectID": "Python/vertex_ai_textgen.html",
    "href": "Python/vertex_ai_textgen.html",
    "title": "Interact with Google’s Vertex AI Text Generation Models",
    "section": "",
    "text": "This provides a minimal example of how to interact with Google’s Text-Bison model – a text generation model offered through GCP’s VertexAI suite of tools.\n#if aiplatform isn't installed, do that\npip install --upgrade google-cloud-aiplatform\nThis will show how to pass a prompt and some hyperparameters to the text generation model, then view a response passed back.\nimport vertexai\nfrom vertexai.languagemodels import TextGenerationModel\n\n#you might need to initiate a project\nvertexai.init(project=\"my-project-id\")\n\n#instantiate a model\nmodel = TextGenerationModel.from_pretrained(\"text-bison@001\")\nIn the above, \"text-bison@001\" is the model we’re passing our prompt to. This is an ok default, but we might want to see the list of available models to choose a different one. This is especiall true if we need to pass a large piece of text to a model.\n#p is our prompt\np = \"Generate 10 interview questions that would be suitable to ask a candidate for an educational researcher position\"\n\n#obviously we can tweak these as needed\n#but these feel like decent defaults\nparams = {\n    \"temperature\": 0.2,\n    \"top_p\": 0.9,\n    \"top_k\": 40,\n    \"max_output_tokens\": 1024\n}\n\n#hit the model and get a response\nresp = model.predict(p, **params)\n\n#view the text from the response\nprint(resp.text)"
  },
  {
    "objectID": "R/color_text_ggplot.html",
    "href": "R/color_text_ggplot.html",
    "title": "Adding Colored Text to ggplot",
    "section": "",
    "text": "Sometimes using colored text in lieu of a legend can make plots more appealling. This is most often the case when showing data for a small number (2 or 3) different groups.\n\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(palmerpenguins) \nlibrary(harrypotter)\nlibrary(glue)\n\ntheme_set(theme_minimal())\n\npal &lt;- hp(n = 3, option = \"HermioneGranger\")\n\nFor example, imagine we want to plot the bill length vs bill depth of different penguin species. One way to do that would be as follows:\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  labs(\n    title = \"Bill Length vs Bill Depth by Species\"\n  ) +\n  scale_color_hp(discrete = TRUE, option = \"HermioneGranger\")\n\n\n\n\nThis is fine, but we might want to get rid of the legend and explicitly denote species/color mappings in the plot title. We can do that as follows.\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point() +\n  labs(\n    title = glue(\"Bill Length vs Bill Depth for &lt;span style='color:{pal[1]}'&gt;Adelie&lt;/span&gt;, &lt;span style='color:{pal[2]}'&gt;Chinstrap&lt;/span&gt;, and &lt;span style='color:{pal[3]}'&gt;Gentoo&lt;/span&gt; Penguins\")\n  ) +\n  scale_color_hp(discrete = TRUE, option = \"HermioneGranger\") +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_markdown()\n  )\n\n\n\n\nThe key to the above is the &lt;span&gt; tags in the title as well as the plot.title = element_markdown() argument in the theme. All in all, this requires a little bit more setup, but I think the plot looks cleaner/more refined."
  },
  {
    "objectID": "R/pre_alloc_loops.html",
    "href": "R/pre_alloc_loops.html",
    "title": "Pre-Allocating to Improve For Loops",
    "section": "",
    "text": "How to pre-allocate vectors used in your for loops in R to make your code run faster and perform fewer allocations.\nFirst, set n to be the size of the vector we want to work with\n\nn &lt;- 1e6\n\nThen set up a function that doesn’t pre-allocate a list\n\nno_alloc &lt;- function(n) {\n\n    x &lt;- list()\n\n    for (i in seq_len(n)) {\n        x[[i]] &lt;- i\n    }\n\n    x\n}\n\nThen set up a function that does pre-allocate a list\n\npre_alloc &lt;- function(n) {\n    \n    x &lt;- vector(mode = \"list\", length = n)\n\n    for (i in seq_len(n)) {\n        x[[i]] &lt;- i\n    }\n    \n    x\n}\n\nAnd compare the benchmarks for these functions\n\nlibrary(bench)\n\nres &lt;- bench::mark(\n    no_alloc(n),\n    pre_alloc(n)\n)\n\nWarning: Some expressions had a GC in every iteration; so filtering is disabled.\n\nres[c(\"expression\", \"min\", \"median\", \"itr/sec\", \"n_gc\")]\n\n# A tibble: 2 × 4\n  expression        min   median `itr/sec`\n  &lt;bch:expr&gt;   &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt;\n1 no_alloc(n)   660.4ms  660.4ms      1.51\n2 pre_alloc(n)   60.6ms   64.6ms     12.6 \n\n\nWe can see that pre-allocating is the way to go!"
  },
  {
    "objectID": "R/s3.html",
    "href": "R/s3.html",
    "title": "S3 Methods",
    "section": "",
    "text": "Below is a sort of minimal example of S3 methods, including how to define them for various classes.\n\nDefine a Generic\n\ncombine &lt;- function(x) {\n    UseMethod(\"combine\")\n} \n\n\n\nDefine and Instantiate Some Classes\n\n# constructor for a new instance of 'my_class'\nnew_my_class &lt;- function(x, y) {\n    stopifnot(is.character(x) & is.character(y))\n\n    structure(\n        list(x = x, y = y),\n        class = \"my_class\"\n    )\n} \n\n# constructor for a new instance of 'your_class'\nnew_your_class &lt;- function(x, y) {\n    stopifnot(is.numeric(x) & is.numeric(y))\n\n    structure(\n        list(x = x, y = y),\n        class = \"your_class\"\n    )\n}\n\na &lt;- new_my_class(\"aaa\", \"bbb\")\nb &lt;- new_your_class(1, 2)\n\n\n\nDefine Combine Methods for Each Class\n\ncombine.my_class &lt;- function(x) {\n    paste0(\n        vctrs::field(x, \"x\"),\n        vctrs::field(x, \"y\")\n    )\n} \n\ncombine.your_class &lt;- function(x) {\n    a &lt;- vctrs::field(x, \"x\")\n    b &lt;- vctrs::field(x, \"y\")\n\n    a + b\n}\n\n\n\nCall Methods\n\ncombine(a) \n\n[1] \"aaabbb\"\n\n\n\ncombine(b) \n\n[1] 3\n\n\nhuzzah!"
  },
  {
    "objectID": "R/tidymodels_workflow.html",
    "href": "R/tidymodels_workflow.html",
    "title": "Tidymodels Workflow",
    "section": "",
    "text": "Below is a minimal (yet complete) example of a machine learning pipeline that use’s R’s tidymodels framework and the Palmer Penguins dataset.\nNote that the goal here isn’t necessarily to fit the best model or demonstrate all of the features; rather it’s just to demonstrate a tidymodels workflow.\n\nlibrary(tidymodels)\nlibrary(tidyverse)\n\nset.seed(0408)\n\n# there's a package for this, but let's just grab the csv\npenguins &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv\")\n\n# drop rows missing body mass\npenguins_complete &lt;- penguins |&gt;\n    filter(!is.na(body_mass_g))\n\n# split the data into training and validation\npenguins_split &lt;- initial_split(penguins, prop = .8)\n\ntrn &lt;- training(penguins_split)\nval &lt;- testing(penguins_split)\n\n# define a recipe for preprocessing\npenguins_rec &lt;- recipe(body_mass_g ~ ., data = trn) |&gt;\n    step_impute_mode(all_nominal_predictors()) |&gt;\n    step_impute_mean(all_numeric_predictors()) |&gt;\n    step_normalize(all_numeric_predictors()) |&gt;\n    step_dummy(all_nominal_predictors())\n\n# define a model specification\nlm_spec &lt;- linear_reg() |&gt;\n    set_engine(\"lm\")\n\n# define a workflow with our preprocessor and our model\nwf &lt;- workflow(penguins_rec, lm_spec)\n\n# fit the workflow\nwf_fit &lt;- wf |&gt;\n    fit(data = trn)\n\n# predict testing data\ny_hat &lt;- unlist(predict(wf_fit, new_data = val))\n\n# estimate performance\neval_tbl &lt;- tibble(\n    truth = val$body_mass_g,\n    estimate = y_hat\n)\n\nrmse(eval_tbl, truth, estimate)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        315."
  },
  {
    "objectID": "Stats/gradient_descent.html",
    "href": "Stats/gradient_descent.html",
    "title": "Gradient Descent",
    "section": "",
    "text": "An example of estimating linear regression beta coefficients via gradient descent, using Julia.\n\nusing Random\nusing ForwardDiff\nusing Distributions\nusing Statistics\n\n\nGenerate Data\nFirst, we generate some fake data\n\nRandom.seed!(0408)\n\n#x data\n𝐗 = hcat(ones(1000), randn(1000, 3))\n\n#ground truth betas\n𝚩 = [.5, 1, 2, 3]\n\n#multiply data by betas\nf₁(X) = X*𝚩\n\n#make some error\nϵ = rand(Normal(0, .5), size(𝐗)[1])\n\n#generate y\ny = f₁(𝐗) + ϵ;\n\n\n\nDefine a Loss Function\nMean squared error is the most straightforward\n\nfunction mse_loss(X, y, b)\n    ŷ = X*b\n\n    l = mean((y .- ŷ).^2)\n\n    return l\nend\n\nmse_loss (generic function with 1 method)\n\n\n\n\nDefine a training function\nThis implements the gradient descent algorithm:\n\ninitialize some random beta values\ninitialize error as some very large number (the init value doesn’t really matter as long as it’s greater than the function’s tol parameter)\ninitialize the number of iterations (iter) at 0\ndefine a function d() to get the gradient of the loss function at a given set of betas\ndefine a loop that updates the beta values by the learning rate * the gradients until convergence\n\n\nfunction grad_descent(X, y; lr = .01, tol = .01, max_iter = 1_000, noisy = false)\n   #randomly initialize betas\n   β = rand(size(X)[2])\n   \n    #init error to something large\n    err = 1e10\n\n    #initialize iterations at 0\n    iter = 0\n\n    #define a function to get the gradient of the loss function at a given set of betas\n    d(b) = ForwardDiff.gradient(params -&gt; mse_loss(X, y, params), b)\n\n    while err &gt; tol && iter &lt; max_iter\n        β -= lr*d(β)\n        err = mse_loss(X, y, β)\n        if (noisy == true)\n            println(\"Iteration $(iter): current error is $(err)\")\n        end\n        iter += 1\n    end\n    return β\nend\n\ngrad_descent (generic function with 1 method)\n\n\n\n\nEstimate βs\nTo estimate the betas, we just run the function\n\nb = grad_descent(𝐗, y)\n\n4-element Vector{Float64}:\n 0.5220524143318362\n 0.992503536801155\n 1.9951668587882012\n 2.997961983119764\n\n\n\n\nCheck Solution Against Base Julia Solver\n\n𝐗 \\ y .≈ b\n\n4-element BitVector:\n 1\n 1\n 1\n 1\n\n\nhuzzah!"
  },
  {
    "objectID": "Stats/mle_lm.html",
    "href": "Stats/mle_lm.html",
    "title": "Maximum Likelihood Estimation - Linear Regression",
    "section": "",
    "text": "An example of estimating regression coefficients in a linear model via maximum likelihood, using Julia.\n\nusing Distributions\nusing Random\nusing Optim\nusing GLM\n\n┌ Info: Precompiling Optim [429524aa-4258-5aef-a3af-852621145aeb]\n└ @ Base loading.jl:1664\n\n\n┌ Info: Precompiling GLM [38e38edf-8417-5370-95a0-9cbb8c7f171a]\n└ @ Base loading.jl:1664\n\n\nGenerate some fake data\n\nRandom.seed!(0408)\n\n#x data\n𝐗 = hcat(ones(1000), randn(1000, 3))\n\n#ground truth betas\n𝚩 = [.5, 1, 2, 3]\n\n#multiply data by betas\nf₁(X) = X*𝚩\n\n#make some error\nϵ = rand(Normal(0, .5), size(𝐗)[1])\n\n#generate y\ny = f₁(𝐗) + ϵ;\n\nDefine a function to optimize\n\nfunction mle_lm(x, y, params)\n    b = params[begin:end-1]\n    σ = params[end]\n\n    ŷ = x*b\n\n    residuals = y .- ŷ\n\n    ll = -loglikelihood(Normal(0, σ), residuals)\n\n    return ll\nend\n\nmle_lm (generic function with 1 method)\n\n\nRun the optimization\n\nstart_params = [0.2, .5, 1, 1, 1]\n\nres = optimize(params -&gt; mle_lm(𝐗, y, params), start_params)\n\nOptim.minimizer(res)\n\n5-element Vector{Float64}:\n 0.5220526008168841\n 0.9925044101015756\n 1.9951661029827337\n 2.9979617225853903\n 0.5170359122024899\n\n\nCheck against ‘base’ Julia solution\n\n𝐗 \\ y\n\n4-element Vector{Float64}:\n 0.5220524130050493\n 0.9925035386795751\n 1.9951668631756507\n 2.9979619869409357"
  },
  {
    "objectID": "Stats/turing_lm.html",
    "href": "Stats/turing_lm.html",
    "title": "Bayesian Linear Regression",
    "section": "",
    "text": "An example of using Bayesian methods (via Julia’s Turing.jl) to estimate a linear regression\nLoad Packages\n\nusing Turing\nusing Random\nusing Distributions\nusing LinearAlgebra\nusing Plots\nusing StatsPlots\n\nGenerate some fake data\n\nRandom.seed!(0408)\n\nn = 1000\n\n𝐗 = randn(n, 3)\n\nβ = [1., 2., 3.]\n\nf(x) = .5 .+ x*β\n\nϵ = rand(Normal(0, .2), n)\n\ny = f(𝐗) + ϵ;\n\nDefine a Model\n\n@model function linear_regression(x, y)\n    #housekeeping\n    n_feat = size(x, 2)\n    \n    #priors\n    α ~ Normal(0, 2)\n    σ ~ Exponential(1)\n    b ~ MvNormal(zeros(n_feat), 5 * I)\n\n    #likelihood\n    for i ∈ eachindex(y)\n        y[i] ~ Normal(α + x[i,:]' * b, σ)\n    end\nend\n\nlinear_regression (generic function with 2 methods)\n\n\nCompute Posterior\n\nmodel = linear_regression(𝐗, y)\n\nchn = sample(model, NUTS(), MCMCThreads(), 1_000, 2);\n\nPlot Parameter Posteriors\n\nplot(chn)\n\n\n\n\nPredict Values of Y\n\npred_mod = linear_regression(\n    𝐗, \n    Vector{Union{Missing, Float64}}(undef, length(y))\n)\n\npreds = predict(pred_mod, chn);\n\n#to get summary statistics\nsummarize(preds)\n\n\nSummary Statistics\n  parameters      mean       std   naive_se      mcse         ess      rhat \n      Symbol   Float64   Float64    Float64   Float64     Float64   Float64 \n        y[1]    5.6876    0.2120     0.0047    0.0040   2131.4185    1.0007\n        y[2]   -1.0132    0.2088     0.0047    0.0050   2045.6712    1.0004\n        y[3]   -3.1168    0.2059     0.0046    0.0039   2026.1454    0.9993\n        y[4]    4.5125    0.2042     0.0046    0.0047   1994.3306    0.9997\n        y[5]    2.6687    0.2041     0.0046    0.0036   2064.6256    0.9991\n        y[6]   -1.2255    0.2080     0.0047    0.0049   1836.3394    0.9993\n        y[7]    2.3067    0.2054     0.0046    0.0039   2075.1743    1.0003\n        y[8]    1.1287    0.2042     0.0046    0.0039   1929.8026    0.9999\n        y[9]    0.4400    0.2061     0.0046    0.0041   2109.2564    0.9996\n       y[10]    6.7965    0.2053     0.0046    0.0047   1746.0770    1.0008\n       y[11]   -3.7930    0.2034     0.0045    0.0048   1820.9121    0.9993\n       y[12]    0.4814    0.2053     0.0046    0.0046   1868.2305    0.9996\n       y[13]    2.4322    0.2068     0.0046    0.0045   1941.8888    0.9993\n       y[14]    0.3437    0.2071     0.0046    0.0048   1761.8573    1.0017\n       y[15]   -0.7060    0.2091     0.0047    0.0046   2053.6154    1.0004\n       y[16]    0.3729    0.2086     0.0047    0.0048   1927.2731    0.9993\n       y[17]    1.8546    0.2099     0.0047    0.0047   1810.0899    0.9996\n       y[18]    2.2985    0.2073     0.0046    0.0045   1978.9502    0.9994\n       y[19]   -0.8137    0.2073     0.0046    0.0047   2090.7345    0.9995\n       y[20]    4.8043    0.2024     0.0045    0.0048   1878.8739    0.9993\n       y[21]    3.7083    0.2100     0.0047    0.0052   1885.7547    0.9996\n       y[22]    0.2769    0.2095     0.0047    0.0036   1944.5012    0.9996\n       y[23]   -3.4487    0.2122     0.0047    0.0054   2100.7819    1.0001\n      ⋮           ⋮         ⋮         ⋮          ⋮          ⋮          ⋮\n                                                             977 rows omitted\n\n\n\n\nPlot posterior distribution(s) of the predictions for the first observation:\n\ny_1 = getindex(preds, \"y[1]\")\n\ndensity(y_1.data)\n\n\n\n\nAnd to get mean predicted values for each observation of y:\n\nmean_preds = summarize(preds)[:, 2]\n\n1000-element Vector{Float64}:\n  5.687584896870903\n -1.0131932466821032\n -3.116780621735853\n  4.512509987465371\n  2.6687246425133946\n -1.2254837248151988\n  2.306673192525782\n  1.1286618139435005\n  0.44000862835633064\n  6.79652703562579\n -3.79298730457439\n  0.48144060256761656\n  2.4321882922004816\n  ⋮\n -3.662775430736099\n  0.7859815782511625\n -3.5565609003804592\n -0.9696845244200145\n  0.82043625177212\n  4.348165410409958\n  1.9125271244452688\n  1.072526007780797\n -7.133862685203614\n -6.206271121676054\n -7.631370737446044\n  0.7668219857089003"
  },
  {
    "objectID": "Writing/busy_readers.html",
    "href": "Writing/busy_readers.html",
    "title": "Writing for Busy Readers",
    "section": "",
    "text": "A few months ago, I read Writing for Busy Readers and absolutely loved it. I would 100% recommend it to anyone with a job that involves even a teeny bit of writing.\nThe whole book is worth reading, but I wanted to post a link to their 1-pager cheat sheet here where I can more easily find it."
  }
]