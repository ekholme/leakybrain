{
  "hash": "3af0c68153e9ba801d7d7118bc18dc9f",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Bootstrapping\"\ndescription: |\n    Illustrated using Julia\ndate: 2024-10-18\nformat:\n  html:\n    code-fold: false\nexecute:\n  freeze: true\nengine: julia\n---\n\n\n\n## What is Bootstrapping\n\n[Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) is a method for estimating the properties of some quantity -- like its expected value, its variance, etc -- using resampling with replacement.\n\nBasically the idea is that, when we have a sample, we can estimate quantities (e.g. the mean) from that sample. But we know that the sample isn't going to be a perfect representation of the population, and that if we obtained data from multiple samples, our estimate of the mean (or whatever other quantity) would differ. Bootstrapping gives us a tool to estimate this variability in our quantity of interest without having to collect multiple samples.\n\nIt can be a nice approach for obtaining (more) stable estimates with small data sets, with datasets that are non-normal, or with data where outliers might bias the estimates. A benefit of bootstrapping is that it makes no assumptions about the distribution of your data, hence its robustness to outliers, small data, non-normality, etc.\n\n## How It Works\n\nBootstrapping works by resampling *with replacement* from a sample, estimating the quantity of interest, and then repeating this process lots of times -- often 1,000 or more. After all of these repetitions, we then have a distribution of the quantity of interest, so we can get a sense of its expected value as well as its standard error. This approach lends itself well to constructing confidence intervals, too.\n\nThe general process is:\n\n1. If you have a dataset *x* (vector, matrix, whatever) with *i* observations, resample *i* observations with replacement from *x*. Note that you don't have to retain *i* samples in your new sample, but it's kind of the default approach.\n2. Estimate your quantity of interest (e.g. mean, quantile, regression coefficient, whatever) on your resampled dataset.\n3. Repeat the process *n* times, where *n* is a fairly large number (usually at least 1,000).\n4. Use your *n* estimates as the distribution of your quantity. You can use this to calculate the mean, standard error, confidence intervals, etc.\n\n## Implementation\n\nBelow is a basic demonstration (in Julia) of bootstrapping to estimate various percentiles of a distribution.\n\n\n\n::: {#2 .cell execution_count=1}\n``` {.julia .cell-code}\nusing Distributions\nusing Random\n\nRandom.seed!(0408)\n\n#generate some data\nu = Uniform(0, 1)\nn = 1_000\nv = rand(u, n)\n\n#define the percentiles I'm interested in\nqs = [0.1, 0.25, 0.5, 0.75, 0.9]\n\n# write a function to bootstrap these quantiles\nfunction boot_quants(x::Vector{Float64}, quants::Vector{Float64}, nboot::Int)\n    qlen = length(quants)\n    x_size = length(x)\n    outvec = [Vector{Float64}(undef, qlen) for _ in 1:nboot]\n\n    for i âˆˆ eachindex(outvec)\n        s = sample(x, x_size, replace=true)\n        outvec[i] = quantile(s, quants)\n    end\n\n    m = hcat(outvec...)'\n\n    return m\nend\n\n# run the function\nres = boot_quants(v, qs, n)\n\n#estimate the expected value of each quantile\n#but note that we could construct confidence intervals or estimate other quantities as well if we wanted\nev_quantiles = mean.(eachcol(res))\n\nev_quantiles\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n5-element Vector{Float64}:\n 0.10801858903776344\n 0.24944167231770148\n 0.5012088237766292\n 0.755182927580556\n 0.8944670802362316\n```\n:::\n:::\n\n\n",
    "supporting": [
      "bootstrap_files"
    ],
    "filters": [],
    "includes": {}
  }
}