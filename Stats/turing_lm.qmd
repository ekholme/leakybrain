---
title: "Bayesian Linear Regression"
description: |
    Illustrated using Julia
date: "2022-12-14"
format:
    html:
        code-fold: false
jupyter: julia-1.8
---

An example of using Bayesian methods (via Julia's `Turing.jl`) to estimate a linear regression

# Load Packages

```{julia}
using Turing
using Random
using Distributions
using LinearAlgebra
using Plots
using StatsPlots

```

# Generate some fake data

```{julia}
Random.seed!(0408)

n = 1000

𝐗 = randn(n, 3)

β = [1., 2., 3.]

f(x) = .5 .+ x*β

ϵ = rand(Normal(0, .2), n)

y = f(𝐗) + ϵ;

```

# Define a Model

```{julia}
@model function linear_regression(x, y)
    #housekeeping
    n_feat = size(x, 2)
    
    #priors
    α ~ Normal(0, 2)
    σ ~ Exponential(1)
    b ~ MvNormal(zeros(n_feat), 5 * I)

    #likelihood
    for i ∈ eachindex(y)
        y[i] ~ Normal(α + x[i,:]' * b, σ)
    end
end


```

# Compute Posterior

```{julia}
#|warning: false
model = linear_regression(𝐗, y)

chn = sample(model, NUTS(), MCMCThreads(), 1_000, 2);

```

# Plot Parameter Posteriors

```{julia}
plot(chn)
```

# Predict Values of Y

```{julia}
pred_mod = linear_regression(
    𝐗, 
    Vector{Union{Missing, Float64}}(undef, length(y))
)

preds = predict(pred_mod, chn);

#to get summary statistics
summarize(preds)

```

Plot posterior distribution(s) of the predictions for the first observation:

```{julia}
y_1 = getindex(preds, "y[1]")

density(y_1.data)
```

And to get mean predicted values for each observation of y:

```{julia}
mean_preds = summarize(preds)[:, 2]
```